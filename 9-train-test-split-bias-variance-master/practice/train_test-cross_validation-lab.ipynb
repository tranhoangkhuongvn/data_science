{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://imgur.com/1ZcRyrc.png\" style=\"float: left; margin: 20px; height: 55px\">\n",
    "\n",
    "# Train-test Split and Cross-Validation Lab\n",
    "\n",
    "_Authors: Joseph Nelson (DC), Kiefer Katovich (SF)_\n",
    "\n",
    "---\n",
    "\n",
    "## Review of train/test validation methods\n",
    "\n",
    "We've discussed overfitting, underfitting, and how to validate the \"generalizeability\" of your models by testing them on unseen data. \n",
    "\n",
    "In this lab you'll practice two related validation methods: \n",
    "1. **train/test split**\n",
    "2. **k-fold cross-validation**\n",
    "\n",
    "Train/test split and k-fold cross-validation both serve two useful purposes:\n",
    "- We prevent overfitting by not using all the data, and\n",
    "- We retain some remaining data to evaluate our model.\n",
    "\n",
    "In the case of cross-validation, the model fitting and evaluation is performed multiple times on different train/test splits of the data.\n",
    "\n",
    "Ultimately we can the training and testing validation framework to compare multiple models on the same dataset. This could be comparisons of two linear models, or of completely different models on the same data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instructions\n",
    "\n",
    "For your independent practice, fit **three different models** on the Boston housing data. For example, you could pick three different subsets of variables, one or more polynomial models, or any other model that you like. \n",
    "\n",
    "**Start with train/test split validation:**\n",
    "* Fix a testing/training split of the data\n",
    "* Train each of your models on the training data\n",
    "* Evaluate each of the models on the test data\n",
    "* Rank the models by how well they score on the testing data set.\n",
    "\n",
    "**Then try K-Fold cross-validation:**\n",
    "* Perform a k-fold cross validation and use the cross-validation scores to compare your models. Did this change your rankings?\n",
    "* Try a few different K-splits of the data for the same models.\n",
    "\n",
    "If you're interested, try a variety of response variables.  We start with **MEDV** (the `.target` attribute from the dataset load method)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "%matplotlib inline\n",
    "\n",
    "plt.style.use('fivethirtyeight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_boston\n",
    "\n",
    "boston = load_boston()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>0.06263</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.593</td>\n",
       "      <td>69.1</td>\n",
       "      <td>2.4786</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>391.99</td>\n",
       "      <td>9.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>0.04527</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.120</td>\n",
       "      <td>76.7</td>\n",
       "      <td>2.2875</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>0.06076</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.976</td>\n",
       "      <td>91.0</td>\n",
       "      <td>2.1675</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>0.10959</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.794</td>\n",
       "      <td>89.3</td>\n",
       "      <td>2.3889</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>393.45</td>\n",
       "      <td>6.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505</th>\n",
       "      <td>0.04741</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.030</td>\n",
       "      <td>80.8</td>\n",
       "      <td>2.5050</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>7.88</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        CRIM   ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD    TAX  \\\n",
       "501  0.06263  0.0  11.93   0.0  0.573  6.593  69.1  2.4786  1.0  273.0   \n",
       "502  0.04527  0.0  11.93   0.0  0.573  6.120  76.7  2.2875  1.0  273.0   \n",
       "503  0.06076  0.0  11.93   0.0  0.573  6.976  91.0  2.1675  1.0  273.0   \n",
       "504  0.10959  0.0  11.93   0.0  0.573  6.794  89.3  2.3889  1.0  273.0   \n",
       "505  0.04741  0.0  11.93   0.0  0.573  6.030  80.8  2.5050  1.0  273.0   \n",
       "\n",
       "     PTRATIO       B  LSTAT  \n",
       "501     21.0  391.99   9.67  \n",
       "502     21.0  396.90   9.08  \n",
       "503     21.0  396.90   5.64  \n",
       "504     21.0  393.45   6.48  \n",
       "505     21.0  396.90   7.88  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = pd.DataFrame(boston.data, columns=boston.feature_names)\n",
    "y = boston.target\n",
    "X.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Clean up any data problems\n",
    "\n",
    "Load the Boston housing data.  Fix any problems, if applicable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CRIM 0 0\n",
      "ZN 0 0\n",
      "INDUS 0 0\n",
      "CHAS 0 0\n",
      "NOX 0 0\n",
      "RM 0 0\n",
      "AGE 0 0\n",
      "DIS 0 0\n",
      "RAD 0 0\n",
      "TAX 0 0\n",
      "PTRATIO 0 0\n",
      "B 0 0\n",
      "LSTAT 0 0\n"
     ]
    }
   ],
   "source": [
    "for c in df.columns.values:\n",
    "    print(c, sum(df[c].isna()), sum(df[c].isnull()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Select 3-4 variables with your dataset to perform a 50/50 test train split on\n",
    "\n",
    "- Use sklearn.\n",
    "- Score and plot your predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "features = ['AGE','CRIM','RAD']\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.8, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "68.55897396025553"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import metrics\n",
    "\n",
    "lr = LinearRegression().fit(X_train, y_train)\n",
    "y_pred = lr.predict(X_test)\n",
    "metrics.mean_squared_error(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Try 70/30 and 90/10\n",
    "- Score and plot.  \n",
    "- How do your metrics change?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Try K-Folds cross-validation with K between 5-10 for your regression. \n",
    "\n",
    "- What seems optimal? \n",
    "- How do your scores change?  \n",
    "- What the variance of scores like?\n",
    "- Try different folds to get a sense of how this impacts your score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.05555556, 0.11111111, 0.16666667, 0.22222222,\n",
       "       0.27777778, 0.33333333, 0.38888889, 0.44444444, 0.5       ])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "alphas = np.linspace(0.01, 0.5, 10)\n",
    "\n",
    "mses = []\n",
    "\n",
    "for a in alphas:\n",
    "    ridgereg = Lasso(alpha=a)\n",
    "\n",
    "    mses.append(np.mean(cross_val_score(ridgereg, X_train, y_train, cv=100, \n",
    "                        scoring='neg_mean_squared_error')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-31.293894730646233,\n",
       " -31.818227946801148,\n",
       " -31.527477891830475,\n",
       " -31.419666497328272,\n",
       " -31.55018569191351,\n",
       " -31.654101530066296,\n",
       " -31.836069487990045,\n",
       " -32.103273460566854,\n",
       " -32.41139674469883,\n",
       " -32.760206503992706]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.22222222, 0.27777778])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alphas[4:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25.518996223195643\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('CRIM', -0.07574970712776749),\n",
       " ('ZN', 0.004419733496652104),\n",
       " ('INDUS', 0.06726086615398488),\n",
       " ('CHAS', 4.943380038011323),\n",
       " ('NOX', -9.912838150969623),\n",
       " ('RM', 5.052818564554981),\n",
       " ('AGE', -0.02416782148424126),\n",
       " ('DIS', -0.8961156250355842),\n",
       " ('RAD', 0.040112905954081415),\n",
       " ('TAX', 0.0007366253898273002),\n",
       " ('PTRATIO', -1.0032794157151608),\n",
       " ('B', 0.011350619966219763),\n",
       " ('LSTAT', -0.3842038940875475)]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridgereg = Lasso(alpha=alphas[0], normalize=True)\n",
    "\n",
    "ridgereg.fit(X_train, y_train)\n",
    "\n",
    "# Predict with fitted model.\n",
    "y_pred = ridgereg.predict(X_test)\n",
    "\n",
    "print(metrics.mean_squared_error(y_pred, y_test))\n",
    "\n",
    "list(zip(boston.feature_names, ridgereg.coef_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. [Bonus] optimize the $R^2$ score\n",
    "\n",
    "Can you optimize your R^2 by selecting the best features and validating the model using either train/test split or K-Folds?\n",
    "\n",
    "Your code will need to iterate through the different combinations of predictors, cross-validate the current model parameterization, and determine which set of features performed best.\n",
    "\n",
    "The number of K-folds is up to you.\n",
    "\n",
    "> *Hint:* the `itertools` package is useful for combinations and permutations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# A:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Can you explain what could be wrong with this approach?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# A:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. [Bonus] Explore another target variable and practice `patsy` formulas\n",
    "\n",
    "Can you find another response variable, given a combination of predictors, that can be predicted accurately through the exploration of different predictors in this dataset?\n",
    "\n",
    "**Try out using patsy to construct your target and predictor matrices from formula strings.**\n",
    "\n",
    "> *Tip: Check out pairplots, coefficients, and pearson scores.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import patsy\n",
    "\n",
    "# A:"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
